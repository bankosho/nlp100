{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第5章: 係り受け解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "夏目漱石の小説『吾輩は猫である』の文章（neko.txt）をCaboChaを使って係り受け解析し，その結果をneko.txt.cabochaというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import CaboCha\n",
    "with open('neko.txt') as f,open('neko.txt.cabocha', 'w') as out_file:\n",
    "    c = CaboCha.Parser()\n",
    "    for line in f:\n",
    "        out_file.write(c.parse(line).toString(CaboCha.FORMAT_LATTICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. 係り受け解析結果の読み込み（形態素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface[　]\tbase[　]\tpos[記号]\tpos1[空白]\n",
      "surface[吾輩]\tbase[吾輩]\tpos[名詞]\tpos1[代名詞]\n",
      "surface[は]\tbase[は]\tpos[助詞]\tpos1[係助詞]\n",
      "surface[猫]\tbase[猫]\tpos[名詞]\tpos1[一般]\n",
      "surface[で]\tbase[だ]\tpos[助動詞]\tpos1[*]\n",
      "surface[ある]\tbase[ある]\tpos[助動詞]\tpos1[*]\n",
      "surface[。]\tbase[。]\tpos[記号]\tpos1[句点]\n"
     ]
    }
   ],
   "source": [
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "    def __str__(self):\n",
    "        return 'surface[{}]\\tbase[{}]\\tpos[{}]\\tpos1[{}]'\\\n",
    "            .format(self.surface, self.base, self.pos, self.pos1)\n",
    "with open('neko.txt.cabocha') as f:\n",
    "    morphs=[]\n",
    "    list_1=[]\n",
    "    for line in f:\n",
    "        if 'EOS'in line:\n",
    "            list_1.append(morphs)\n",
    "            morphs=[]\n",
    "        else:\n",
    "            if line[0]=='*':\n",
    "                continue\n",
    "            else:\n",
    "                b_1=line.split('\\t')[0]\n",
    "                b_2=line.split('\\t')[1].split(',')\n",
    "            \n",
    "                morphs.append(Morph(b_1,b_2[6],b_2[0],b_2[1]))\n",
    "\n",
    "for i in list_1[2]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]吾輩は\tsrcs[]\tdst[5]\n",
      "[1]ここで\tsrcs[]\tdst[2]\n",
      "[2]始めて\tsrcs[1]\tdst[3]\n",
      "[3]人間という\tsrcs[2]\tdst[4]\n",
      "[4]ものを\tsrcs[3]\tdst[5]\n",
      "[5]見た。\tsrcs[0, 4]\tdst[-1]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "class Chunk:\n",
    "    def __init__(self):\n",
    "        self.morphs = []\n",
    "        self.srcs = []\n",
    "        self.dst = -1\n",
    "    def __str__(self):\n",
    "        surface = ''\n",
    "        for morph in self.morphs:\n",
    "            surface += morph.surface\n",
    "        return '{}\\tsrcs{}\\tdst[{}]'.format(surface, self.srcs, self.dst)\n",
    "    def fuhao(self):\n",
    "        result = ''\n",
    "        for morph in self.morphs:\n",
    "            if morph.pos != '記号':\n",
    "                result += morph.surface\n",
    "        return result\n",
    "    def chk_pos(self, pos):\n",
    "        for morph in self.morphs:\n",
    "            if morph.pos == pos:\n",
    "                return True\n",
    "        return False\n",
    "    def get_morphs_by_pos(self, pos):\n",
    "        return [res for res in self.morphs if res.pos == pos]\n",
    "    def get_kaku(self):\n",
    "        auxs = self.get_morphs_by_pos('助詞')\n",
    "        if len(auxs) > 0:\n",
    "            return auxs[-1].surface \n",
    "        else:\n",
    "            return ''\n",
    "    def get_sahen(self):\n",
    "        for i, morph in enumerate(self.morphs[0:-1]):\n",
    "            if (morph.pos == '名詞') \\\n",
    "                    and (morph.pos1 == 'サ変接続') \\\n",
    "                    and (self.morphs[i + 1].pos == '助詞') \\\n",
    "                    and (self.morphs[i + 1].surface == 'を'):\n",
    "                return morph.surface + self.morphs[i + 1].surface\n",
    "        return ''\n",
    "    def noun_change(self,symbol,omit=False):\n",
    "        result=''\n",
    "        for morph in self.morphs:\n",
    "            if morph.pos!='記号':\n",
    "                if morph.pos=='名詞':\n",
    "                    result+=symbol\n",
    "                    if omit:\n",
    "                        return result\n",
    "                else:\n",
    "                    result+=morph.surface\n",
    "        return result\n",
    "\n",
    "def function_1():\n",
    "    with open('neko.txt.cabocha') as file_parsed:\n",
    "        chunks = dict() \n",
    "        idx = -1\n",
    "        for line in file_parsed:\n",
    "            if line == 'EOS\\n':\n",
    "                if len(chunks) > 0:\n",
    "                    sorted_tuple = sorted(chunks.items(), key=lambda x: x[0])\n",
    "                    yield list(zip(*sorted_tuple))[1]\n",
    "                    chunks.clear()\n",
    "                else:\n",
    "                    yield []\n",
    "            elif line[0] == '*':\n",
    "                cols = line.split(' ')\n",
    "                idx = int(cols[1])\n",
    "                dst = int(re.search(r'(.*?)D', cols[2]).group(1))\n",
    "                if idx not in chunks:\n",
    "                    chunks[idx] = Chunk()\n",
    "                chunks[idx].dst = dst\n",
    "                if dst != -1:\n",
    "                    if dst not in chunks:\n",
    "                        chunks[dst] = Chunk()\n",
    "                    chunks[dst].srcs.append(idx)\n",
    "            else:\n",
    "                cols = line.split('\\t')\n",
    "                res_cols = cols[1].split(',')\n",
    "                chunks[idx].morphs.append(\n",
    "                    Morph(cols[0],res_cols[6],res_cols[0],res_cols[1]))\n",
    "        raise StopIteration\n",
    "for i, chunks in enumerate(function_1(), 1):\n",
    "    if i == 8:\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            print('[{}]{}'.format(j, chunk))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. 係り元と係り先の文節の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩は\t猫である\n",
      "名前は\t無い\n",
      "まだ\t無い\n",
      "どこで\t生れたか\n",
      "生れたか\tつかぬ\n",
      "とんと\tつかぬ\n",
      "見当が\tつかぬ\n",
      "何でも\t薄暗い\n",
      "薄暗い\t所で\n",
      "じめじめした\t所で\n"
     ]
    }
   ],
   "source": [
    "list_1=[]\n",
    "for chunks in function_1():\n",
    "    for chunk in chunks:\n",
    "        if int(chunk.dst)!=-1:\n",
    "            a=chunk.fuhao()\n",
    "            b=chunks[int(chunk.dst)].fuhao()\n",
    "            if a!='' and b!='':\n",
    "                list_1.append(a+'\\t'+b)\n",
    "for i in range(10):\n",
    "    print(list_1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "どこで\t生れたか\n",
      "見当が\tつかぬ\n",
      "所で\t泣いて\n",
      "ニャーニャー\t泣いて\n",
      "いた事だけは\t記憶している\n",
      "吾輩は\t見た\n",
      "ここで\t始めて\n",
      "ものを\t見た\n",
      "あとで\t聞くと\n",
      "我々を\t捕えて\n"
     ]
    }
   ],
   "source": [
    "list_2=[]\n",
    "for chunks in function_1():\n",
    "    for chunk in chunks:\n",
    "        if int(chunk.dst) != -1:\n",
    "            if chunk.chk_pos('名詞') and chunks[int(chunk.dst)].chk_pos('動詞'):\n",
    "                c = chunk.fuhao()\n",
    "                d = chunks[int(chunk.dst)].fuhao()\n",
    "                if c != '' and d != '':\n",
    "                    list_2.append(c+'\\t'+d)\n",
    "for i in range(10):\n",
    "    print(list_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. 係り受け木の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字列:吾輩はここで始めて人間というものを見た。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import CaboCha\n",
    "import pydot_ng as pydot\n",
    "with open('neko_1.txt', mode='w') as out_file:\n",
    "    out_file.write(input('文字列:'))\n",
    "with open('neko_1.txt') as f,open('neko_2.txt', mode='w') as out_file:\n",
    "    c = CaboCha.Parser()\n",
    "    for line in f:\n",
    "        out_file.write(c.parse(line).toString(CaboCha.FORMAT_LATTICE))\n",
    "def function_2():\n",
    "    with open('neko_2.txt') as file_parsed:\n",
    "        chunks = dict() \n",
    "        idx = -1\n",
    "        for line in file_parsed:\n",
    "            if line == 'EOS\\n':\n",
    "                if len(chunks) > 0:\n",
    "                    sorted_tuple = sorted(chunks.items(), key=lambda x: x[0])\n",
    "                    yield list(zip(*sorted_tuple))[1]\n",
    "                    chunks.clear()\n",
    "                else:\n",
    "                    yield []\n",
    "            elif line[0] == '*':\n",
    "                cols = line.split(' ')\n",
    "                idx = int(cols[1])\n",
    "                dst = int(re.search(r'(.*?)D', cols[2]).group(1))\n",
    "                if idx not in chunks:\n",
    "                    chunks[idx] = Chunk()\n",
    "                chunks[idx].dst = dst\n",
    "                if dst != -1:\n",
    "                    if dst not in chunks:\n",
    "                        chunks[dst] = Chunk()\n",
    "                    chunks[dst].srcs.append(idx)\n",
    "            else:\n",
    "                cols = line.split('\\t')\n",
    "                res_cols = cols[1].split(',')\n",
    "                chunks[idx].morphs.append(\n",
    "                    Morph(cols[0],res_cols[6],res_cols[0],res_cols[1]))\n",
    "        raise StopIteration\n",
    "edges=[]\n",
    "for chunks in function_2():\n",
    "    for chunk in chunks:\n",
    "        if chunk.dst!=-1:\n",
    "            a=chunk.fuhao()\n",
    "            b=chunks[chunk.dst].fuhao()\n",
    "            if a!='' and b!='':\n",
    "                edges.append((a,b))\n",
    "graph=pydot.graph_from_edges(edges,directed=True)\n",
    "graph.write_png('result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAAD8CAYAAAABiPQsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXlcVNX//19nhmFRtkBFBENQJO1XiQFqKZg7KW5ZGpJk\nbln60FQMpU+aWi5l9ajc0Nw+fhDL5eOSRepXMU0pScUUFXBBNhGJTXbm/ftjhvnMKMjsdy6e5+Nx\nH9x77lleF15zOXPuuefNiAgcjhiRCC2Aw9EXbl6OaOHm5YgWbl6OaOHm5YgWbl6OaDGZeRljQxhj\n1xhj6YyxaFO1w3lyYaYY52WMSQFcBzAQQBaAPwG8SURXjN4Y54nFVHfeIADpRHSDiKoBxAMYYaK2\nOE8oViaq1wPAHbXjLAA9GsvcqlUr6tChg4mkcMRGcnJyARG1biqfqczbJIyxqQCmAsDTTz+Nc+fO\nCSWFY2Ewxm5rk89U5s0G0F7t2FOZpoKIYgHEAkBAQACfYGEkMjMzkZiYiMTERFy8eBFpaWkoLi5u\nMK9UKkWnTp3g5+eH4OBghISEICAgwMyKDYCIjL5B8aG4AcAbgDWAiwCebSz/iy++SBz92LRpE/n6\n+hIA+uCDD+j3338nuVyuV10ZGRk0efJksre3J5lMRnPmzKG8vDwjK24aAOdIG59pk0mfDcCrUIw4\nZACIeVxebl7tKS4upoEDB5JEIqHFixdTTU2NSds7dOgQeXt7k4uLCyUkJJi0rXoEN68uGzdv0xQW\nFhJjjDZu3CiYhuvXrxMA2r17t0nb0da8/AmbhVNQUABbW1vExcVBLpdj8uTJgmnx9fUFEaF79+5o\n0aIFNm7cKJgWQMDRBk7TPPPMM5gwYQIqKyuFlqKBt7c3ysvLcfv2bTDGkJOTA3d3d7Pr4Oa1QNq1\na4cTJ07g6tWrQkt5LF5eXvXfb2Bvb4/s7Gw4OTmZrX3ebbAwHBwccPv2bXTu3FloKSAiBAUFaZW3\nrKwM3bt3N7EiTbh5LQh/f3/cvXsXMplM57JHjx7Fzz//jAkTJjQ6rqtNHnVCQkJw8uRJrTVkZGQg\nOtp8c7C4eS2ISZMmoUWLFnqVHTBgAC5duoTFixc3+q+7sTyhoaGYNm0aAgMDMX/+fPTs2RM//vgj\ndu7cCVtbW510nD9/HnK5XK9r0BlthiRMvfGhMqKCggKhJRAR0fjx4w2uIyQkxKDy4ENl4uLdd9/V\nu+y9e/eMkqewsBA7duzQW0c9Z8+eNbgObeDmtRAOHTqkd9m5c+caJc+yZcv01qDOsGHDjFJPU3Dz\nWgiMMb3L5uTkaIwFX758Gdu2bdM5T1RUlN4a1CEyzzwrk7xJoSsBAQH0pE+J/P777zFp0iShZQAA\n9u/fj1atWuHll1/Wq7xUKkVdXZ3e7TPGkomoyelt3LwWRE1NjV7DZJbEhQsXkJWVZVDXQVvz8ids\nFoSTkxPKy8uFlmEQgYGBqKmpMUtbvM9rQaSlpWHgwIFCy9Cb69evo6qqymztcfNaEB4eHvjss88Q\nHBwstBSdSUpKwsSJEyGRmM9SvNtgYQQGBmLPnj2wtbVFRUWFQaMQ5iIiIgJeXl44ffq0Wdvl5rVA\nWrdujcrKSnTv3h2DBw/G8uXLhZbUIKmpqejatSvu378PFxcXs7fPuw0WzF9//YWFCxfC0dHRogz8\n999/w9raGikpKSAiQYwLgM9tEBPHjx8nJycn6t+/P926dcts7crlclq0aBEBoLS0NJO3B/4OW/Pm\n6NGj5OfnR1ZWVjRz5ky6ceOG0equqqqitWvXkre3N0mlUlq+fLnR6tYGbc3LH1I0E86cOYOFCxfi\nxIkTAICgoCD4+/vD19cXvr6+cHZ2hoODA6ysrFBWVobS0lLcunULaWlpuHr1Kk6ePImSkhKEhYUh\nPDwcr7/+OqRSqSDXwp+wcVRUVVWhqKgIZWVlqKyshLOzM+zt7c36yo4u8CdsHBU2NjZwc3ODm5sb\namtrYWXVPP7sfLSBI1q4eTmihZuXI1q4eTmihZuXI1q4eTmihZuXI1q4eTmihZuXI1q4eTmihZuX\nI1q4eTmihZuXI1q4eTmihZv3CYExBsYYZDIZGGNYsmSJ0JIMpknzMsY2M8byGWN/q6W5MMaOMMbS\nlD+fUju3gDGWzhi7xhgbbCrhHN14+BX6jz/+WCAlxkObO+9WAEMeSosGcIyIfAEcUx6DMdYVwDgA\nzyrLrGWMCfMuCUeDDRs2qPbFsBaENjRpXiI6CaDwoeQRAOrXx9wGYKRaejwRVRHRTQDpALSLyMEx\nKVOmTFG9k6ZuZDGjb5/XjYhylft5ANyU+x4A7qjly1KmcSwAKysrSKVSTJkyRWgpRsHgL2zKV5V1\nfouTMTaVMXaOMXZOmyXnOYZTWlqK119/XWgZRkPfN/HuMsbciSiXMeYOIF+Zng2gvVo+T2XaIxBR\nLIBYQPH2sJ46OA9x//59JCYmIjExERcvXkRaWhpycnI08sTHxwNQxHzz9fWFn58fgoODERISgi5d\nugghWz+0WdwBQAcAf6sdfw4gWrkfDWCVcv9ZABcB2ADwBnADgLSp+vmiI/qzc+dO6tatGwGgqVOn\n0pEjR6iqqkqvulJSUujNN98kmUxGLVu2pH/9619UXFxsZMVNA2OtmANgJ4BcADVQ9GEnAXCFYpQh\nDcBRAC5q+WMAZAC4BiBUGxHcvNpTXl5OI0eOJAAUFRVF5eXlJm1v165d5ObmRh4eHnTq1CmTtlWP\n0cxrjo2bt2nKysoIAH399deCaTh//jwxxujw4cMmbUdb8/InbBZOSUkJHBwcsGbNGhARZs2aJZiW\nbt26QS6Xw8vLC9bW1oiLixNMC8BXzLFounXrhqFDh6K0tFRoKRp07doV1dXVuHbtGhhjKCgogKur\nq9l1cPNaIPn5+fDy8kJ5eblFPw3z8/MDEWHChAlo164dVqxYYdb2ebfBwkhKSsIbb7yh95L+N2/e\nNIGqx7N9+3aMHj0avXr1Mmu73LwWRM+ePdG1a1fVMqXaUFJSgvPnzwNQxHFbv349/vnnH4086hF6\nioqKHlt/VVUVfvnlF8ydOxdeXl5a6wgKCsKZM2ewePFircsYjDbf6ky98dEGBV988YVO+ZcsWUKj\nR4+mRYsWkUQiIW9vbyIiqqiooDlz5mjkXbx4MRERderUiTIzMzXOlZeXU1BQEB08eJCIiF599VV9\nL4FCQkJILpfrXZ6ID5WJjsLCQr3KvfLKK0RENH78eHrxxRcpODiY3nvvPXrttdc08jk5OdHx48dV\nY7WBgYEN1hcSEqKXDnX69+9vUHluXpExduxYvcp16tSJiIj279/faJ6lS5fSvn37qK6uTiO9V69e\nGscPn9cXa2trg8pra17e57UQDhw4oFe5yMhIfPzxxxg+fDgmTJiAgoICFBQUoEePHqo8VVVVGDly\nJKytrTXKpqSkaBzv3r1bLw0PY0jcYV3gQ2Ui56OPPoJUKsX8+fNha2uLVq1aAYBGxHZnZ2f89NNP\nOHnypCrt+vXrj3xg3njjDaNoMtfwHjevhaDv3ap///6oq6uDs7MzunTpgq+//hoANAJwz507V7V/\n9+5dzJ49G5MmTcKAAQMeqS8gIADJyckIDw/Hf/7zH700HTp0SK9yOqNN38LUG+/zEhUUFOhc5uzZ\nsxrH27dvV+3v3r3bYE360rdvX4PKg4eyEh8ODg4W9yhYV6RSKerq6gyqQ9toQPwLmwXx999/Iyws\nTGgZenPr1i1UV1ebrT1uXgvCy8sL8+fPx6BBg4SWojMXLlzAa6+9ZtbAg/wLm4XRp08fbN26Ffb2\n9igrKxNajlZMmzYNdnZ2SE5ONmu73LwWSLt27VBWVoYuXbpg/Pjx+Oijj4SW1CA3b96Ej48P8vLy\n4Obm1nQBI8O7DRZMamoqpk+fDjs7O3zzzTdCy1GRkZEBOzs7HD9+HEQkiHEBbl6Lx9XVFRUVFYiM\njIREIkFsbKxgWuonn6ekpKCiogLvvPOOYFoAbl7R4OTkBLlcjjfffBNDhgyBRCLBokWLUFNTY9J2\nDxw4gA4dOqB169bIysoCEWHUqFEmbVNb+DhvM+Ho0aNYuHAh/vzzT8hkMvTu3Rv+/v7w9fWFr68v\nnJ2d4eDgACsrK5SVlaG0tBS3bt1CWloaUlNTcfLkSeTl5aFfv34IDw9HREQEbGxsBLkWbcd5uXmf\nAAoLC1FUVISysjJUVlbC2dkZ9vb2aNeundDSGkRb8/LRhicAFxcXuLi4AABqa2thZdU8/uy8z8sR\nLdy8HNHCzcsRLdy8HNHCzcsRLdy8HNHCzcsRLdy8HNHCzcsRLdy8HNHCzcsRLdy8HNHCzcsRLdy8\nHNHCzfuEwBgDYwwymQyMsScj6jtjrD1j7Dhj7Apj7DJjbJYy3YUxdoQxlqb8+ZRamQWMsXTG2DXG\n2GBTXgBHP5YsWSK0BIPR5s5bC2AuEXUF0BPA+4yxrlBEvjxGRL5QBBSMBgDluXFQRMMcAmAtY8x8\nK1FwGmTt2rVCSzA6TZqXiHKJ6C/lfimAVCgiuY8AsE2ZbRuAkcr9EQDiiaiKiG4CSAcQZGzhHN2Y\nPn06JBLFn7u5GFmnPi9jrAMAfwBJANyIKFd5Kg9A/cv7HgDuqBXLUqZxBMbKygoSiQTTp08XWopR\n0Nq8jDF7AHsAzCaiEvVzymUpdXqTkzE2lTF2jjF27t69e7oU5ejJrl27ms37a4CW5mWMyaAw7n+I\naK8y+S5jzF153h1AvjI9G0B7teKeyjQNiCiWiAKIKKB169b66uc0QU1NDUpLS5Gfn4/u3bvjm2++\nQW5uLoqKilBZWSm0PIPQZrSBAfgeQCoRfal26gCASOV+JID9aunjGGM2jDFvAL4A/jCe5CeTGzdu\nYOLEiWjTpg0YY3BxccHw4cOxatUq/N///R/y8vIaLCeTyeDg4IA2bdrg6aefxrRp0+Du7g5nZ2fY\n2to2WKaiogLJycnYsmULJk2aBD8/PzDGIJVKMXPmTCQmJpryUrWnqdWnAfSGokuQAuCCcnsVgCsU\nowxpAI4CcFErEwMgA8A1AKFNtcFXRtckMzOTZsyYQdbW1mRvb0/Tp09XhaCyBG7dukWrVq2iZ599\nlgDQwIEDKSEhwWj1g4eyEhdHjx4lANSnTx86duyY0HJ0Jicnh9577z2SyWS0YsUKg+ri5hUBP//8\nM9nb21Pfvn0pIyNDaDlGo66ujqKjowkARUVF6Vyem9eCGTZsGHl6ejYrwzaGXC6nt99+mxwdHbW+\nXm3Ny+c2mBF/f3+MHz8eBw8exJ07d+Dj4yO0JJPDGMOWLVtQXFyMixcvqh6UGIPmM+hnwVRXV8PB\nwUEj+vqTyKhRoyCXy+Hu7o4NGzZg+PDhBtXH77wm5uDBgxg4cKDBxm0sqmTnzp0RExMDBwcHREZG\nIiYmBjExMXjppZcazG9onIuRI0diy5YtBj2ly83Nha2tLZ5//nmDtAje36Vm3OeVSCRGq6tz584N\npo8ePZqIiDw9PSkyMlKVvm7dOp3q79Kli8bxa6+91mAk+uTkZJ3qbYqhQ4fSnTt3NNLA+7zCMnz4\ncKM+wfL09Hzs+T179mDcuHFaxUErKirC+++/j/z8fFXaokWLNPLs3r0bQ4cO1UirqanB999/j2XL\nliEnJwfe3t46XEHDHDp0CB07dtSrLDevicjOzoZMJjNKXXV1dRg7duxj86SmpqJfv3746quvGs2z\nfft2bNq0Cc7OzlizZg3atGmjOufu7v5I/lmzZqG4uFh1HBoaijVr1uCjjz5Cu3btjDYnOD09Hfv3\n728640PwL2wmoKioCMuXLzdafeHh4di1axe6du2KK1euNJgnKSkJUqm00Yk3QUFB+OOPxp/SX758\nGcHBwRppY8aMwalTpxASEgJAETpAnca06Er79u0RHh6OESNG6FSO33lNQF1dndEiQVZUVKBFixYA\ngKioqEb/wNnZ2UhNTUVJSUmD5x9nXABYv349tm3bppEmkUhUxm2I1atXP7ZOXdArXrE2HWNTb83x\nC1twcLDBdeTn59PChQs10gYPHkytWrWisrIyIlI88CAiKi0tJSJF9PjCwkLatGmTRrnnnnuOtmzZ\nQpWVlfTf//6XJk+eTH/99ZfqvFwuJ2tra621de/eXa9raoh79+5RXFyc6hj8CZuw9O7dm+Ryud7l\n1f+YD5OUlKTaj4+Pf+T84z44hmgiIpo+fTr99ttvBtXxMPb29hrH2pqXRwMyIVKpVL9/h08QkydP\nxty5c9GlSxdVGo8GZAHU1dVh3bp1+O233xAXFye0HIvi0qVLCA0NRVZWlt518C9sJmb69OlYu3Zt\no0/InkSee+45nDhxwiDjAvzOaxacnZ1BRGjXrh0iIyONOowmJpKTkxEYGAi5XG6U+vid14zk5OTg\nk08+wQsvvICePXuitLRUaElmYfHixZBKpSgvLzeacQHw0QYhWb9+PTHGaMKECaqhr+bC2rVrycrK\nisaOHUu1tbU6lQUfKhMX33//PQGgiIgISktLE1qOzlRXV9PKlSsJAL333ntUWVmpd13cvCLm1KlT\nFBYWRgDIz8+Pli9f/sjMKyGprq6m+Ph4evXVVwkAde7cmWJjYw0eQ66Hm7eZcfz4cerXrx8xxggA\ndevWjWbMmEHx8fEmuVPn5+fTsWPH6JNPPqGBAweSnZ0dAaCwsDDatm0bPXjwwOht1qOteflDimZM\ncXEx7t27h8rKSlRUVKCyshLV1dWwt7eHra0tbG1t4ezsDDc3t6YrMyP8IQUHTk5OcHJy0kirra1t\nNks+8aEyjmjh5uWIFm5ejmjh5uWIFm5ejmjh5uWIFm5ejmjh5uWIFm5ejmjh5uWIFm5ejmjh5uWI\nFm5ejmjh5uWIFm7eJwTGGBhjkMlkYIwhJiZGaEkGo00QQVvG2B+MsYuMscuMsU+U6S6MsSOMsTTl\nz6fUyixgjKUzxq4xxgab8gI4+vHpp58KLcFgtLnzVgHoR0QvAOgGYAhjrCeAaADHiMgXimCC0QDA\nGOsKYByAZwEMAbCWMWacJRM5evPNN98ILcHoNGle5WtF9YEMZMqNAIwAUL8m5jYAI5X7IwDEE1EV\nEd0EkA4gyKiqOTozc+ZMVSSe5mJkbQNnSxljF6AIjn2EiJIAuBFRrjJLHoD6F6E8ANxRK56lTHu4\nTh713cxIJBJIJBLMnDlTaClGQSvzElEdEXWDIoJ7EGPs/z10nqC4G2sN8ajvZmfnzp1GjYMmNDpd\nCREVATgORV/2LmPMHQCUP+ujc2QDaK9WzFOZJjg1NTX4559/kJeXhwcPHggtx6zU1dVh4MCBiI2N\nbTbx4Jp8jZQx1hpADREVMcbsAAwEsBLAAQCRAFYof9ZHxDgAII4x9iWAdgB8ATx+TXkjce7cOcTF\nxSE+Ph65ublwdHREr1694Ovri6CgIDg6OsLe3h42NjYoLS1FWVkZ8vLykJaWhsTERKSkpAAA+vfv\nj/DwcIwbN061pL6lk5aWhgULFuDAgQOoqalBx44d4e/vD19fX/j6+sLZ2Rn29vbo0KEDfv31V5SV\nleHWrVtIS0tDamoqkpKSQESYOHEiwsPDMWDAAKEvqWmaWtgBwPMAzgNIAfA3gI+V6a5QjDKkATgK\nwEWtTAyADADXAIQ21YY+i45s3bqV7Ozs6Pnnnzf5Ol/Hjx8nxhiFhoZScXGxSdtqCrlcTlOnTiUA\nFBkZSdnZ2SZrq66ujr799luys7Ojbt260fXr103WljpojivmFBQUkIeHBwUHB9P9+/f1+sUYysaN\nG0kikdCSJUvM2m5tbS0BeCRGhTlJSEgga2trOnfunEnbaVbmzcrKIisrK1q/fr1BvxRjUl5eTl26\ndKGJEyeatJ2qqipyc3OjuXPnmrQdXThx4gQxxujIkSMmqV9b81r80il79+5Fbm4uampqhJaigZ2d\nHa5cuYLa2lq0adNGI5qksejXrx86duyIvLw8o9dtCCEhIZDL5fj9999hZWWFkpISYb4baONwU2+N\n3Xl9fHzol19+Mcqn2dR4enpqROkxhJKSEpJKpVRdXW2U+kxNaGgorV692mj1Qeyxh6VSKa5fv47B\ng/WfGnH79u1H0ioqKgDoGbTuMdy5cwc//PADvv32W4PqSU1NRXBwMGpra40W/tXUHD58GM8++yxC\nQ0PN2q5FrhKpawioDz74AC1atMD+/ftVESJra2vxzz//IDY2FgCwb98+AIookunp6Zg6dSpGjx6N\nGTNmID09vcF6hw0bhkOHDul0LStXrkTnzp0xatQoncoBwP379zF06FCcPXtW57LGirrZtm1bvbsp\n58+fh7+/v8EatF0lUvAuAz3Ubejdu7feq2pDNRWDKCUlReNcREQELVy4kDp27EhERIMGDaKPP/6Y\n3n//fVWehwPyxcbGEhFRTU2NTjoCAgJ0XsqeiEgmk+lcpp6mNB48eJCWLVtGFy5coHfeeYfS09M1\nzi9btowePHhAU6ZMoTZt2lBUVJReOmxsbPQqpw7EONqwa9cuun37tt4XPX78eCJS/CG3b9/eYJ5d\nu3ZR3759VeOj6n21iooK1X5xcTEtW7ZMby26GrE+/Kq+hIWFNXrO19e3wfTJkydrHA8ZMkTjOC8v\nTy8tQ4cO1atcPdqa16L6vJMmTcLTTz+tU5mcnBzExMRg4cKFaN++PWJiYrBo0SJcvnwZUVFRWLBg\nAQAgISEBe/fuhUwmg0wmQ1JSErp37445c+YAAM6cOQNbW1tVvY6OjnB3d9f7WjZu3IjKykqt80+f\nPl3vtoqKilR9+fHjxz9yftGiRQ2W27Rpk2r/8uXLeOGFF1BQUIDq6mr4+/vj2LFjeulJSEjQq5zO\naONwU2/1d16o/dvXlTFjxtDy5ctV28N1HT16lJYuXUpLly6lgIAAWrp0KVlZWanOb9my5ZE6DRmM\nr6mpoT179midv2XLlnq31bNnT2rfvj29/fbbREQ0c+ZMjfOpqalEpIjQo05oaKhqf8yYMUSk+O+l\ni+6GGDVqlEHlIcY7ryEUFBQgOjpatT1MeXn5I2k2Njaq/ZYtW2Lq1KkAgBEjRqCiogJXr17FgAED\n9JrIouuXztraWp3bqOfMmTM4duwYtmzZAkAxX1c9xtuXX34JIkJZWZkqzcfHB4cPH1Yd//jjj8jL\ny8OOHTvg6uqqtxYAZlt53aLMa8jQUElJCZKSklSbOteuXUNpaSl8fHzg4+ODFi1awMfHB7GxsYiL\ni0Nubi7GjBmj6ia8/PLLmDt3Lk6ePImjR49i7969OuvZt28fBg0apHV+Q4eZIiIiACg+BH5+fnBw\ncFCd27BhA7KyshAVFYU+ffpg8+bNuHHjxiN11E9SDwkJMUjLTz/9ZFB5rdHm9mzqrb7bsGbNGioq\nKtLrX83+/fs1jr/77rtG8/7www96taELjo6OOuXPzc01uM0dO3bQzp07Dapj69attHTpUvr3v/+t\n94SnHj16GKQBYhxtICJycHAw6MItgfz8fFqwYIHO5TZv3mwCNeZl1KhROg8tPoy25rWobgOgeFqz\nevVqoWUYRNu2bfHZZ5/pXG7lypWorq42gSLz0bZtW/NFG9LG4abeHp7bIJfLNUYCxMLOnTspMjLS\noDoOHDhAY8eONY4gM5KRkdHoeLKuQMyzyhhjqKmpQcuWLXHlyhV4eXkJLalJXnnlFbz11lvYunWr\nQfWEhYXBz88PrVu3hlheTP3Xv/6FjIwMXL9+3bwNa+NwU2+Pm88bHR1NZ8+eNfjTbEpeeukljadz\nxqJdu3a0YcMGo9drLAoKCkgqlRo9fCzE2ud9mOXLl6OoqAgSiQTJyclCy9EgIiICL7zwAk6fPq3x\ndM5YZGdnY9CgQZBKpYiPjzd6/fpy//59uLq6YuPGjaitrUWnTp2EEaKNw029afsaUGJiIkkkEpoz\nZ45en2hjcOHCBfLw8HjsXAJTkJmZSTY2NrRv3z6ztqtOfn4+ATD5Gy0Q61CZtsyYMYMA0KRJk3Qu\nqyvFxcXk6elJbdq0oVOnTpm8vceRlZVF/v7+ZGdn99ixbGNx5swZCggIIBsbG4qLizN5e0RPgHnV\nmTdvHllbW5OTkxNNmzaNTpw4QXK5XK+6cnJyaM2aNdS7d28CQD169KC9e/capM9UVFVV0YoVK8jV\n1ZVkMhl9+umnBr3hW1RURB9++CF5eXmp3k6+cuWKERVrh7bmtcjJ6IaSnZ2N48ePIzExEUlJSUhL\nS3vsDC8bGxv06dMHISEh6NatG+Lj47Fjxw6j6TEXCQkJOH/+PGxsbFTrUNy8efOxZVq1agU/Pz/V\n9Q8ZMsRMahtHtJPRLYEpU6boPZdVSNzd3YWWYBTQXEYbhCA2NharVq1q8B04S2X48OHIyckRWoZZ\nsciHFJbA6tWrIZPJLO6V+4a4ffs2OnfuLLQMs8PN+xgqKirQo0ePR6ZYWhq+vr6inxOhD7zb8Bis\nrKwwbtw4nD9/XmgpjRIUFNTgRPsnAX7nbYIPPvgAjo6OKCkpEVrKI/z1118IDw833ywuC+PJvGod\nKSkpwYMHD9CyZUuhpWjQt29fi/xQmQvebdASe3t7oSVo0LFjxyfauAA3r9YUFhYiPDxcaBkAgJ9/\n/hkrVqwQWobgcPNqyVNPPYXY2FiEhYUJquOHH36ARCLB66+/LqgOS4D3eXXA3t4ezzzzDG7duoUO\nHToIomHhwoWNrq32pMHNqyOff/45rK2tBRlXtdRRD6Hg3QY9KC8vR2BgoNnbTUxMNHublgw3rx5Y\nWVkhIiLCrG92BAYGGmX50OYE7zboyaxZs+Dk5ITi4mKTt5WcnIy33nrL5O2IDW5eAyguLoaPj0+D\nSycZk379+pnlQyI2tO42KOMPn2eMHVIeuzDGjjDG0pQ/n1LLu4Axls4Yu8YY039dfhHw+eef4/Dh\nw/jiiy/w8ssvG6XOzZs3q9Yu8/b25sZtBF3uvLMApAJwVB5HAzhGRCsYY9HK4w8ZY10BjAPwLBQR\nMI8yxjoTkXGDQFgIvXr1gqenJ4jIaDEkJk2aBECxfgWPy9w42kZ99wQwFMAmteQRALYp97cBGKmW\nHk9EVUTnnUvRAAAHI0lEQVR0E0A6gCDjyLUsjh07Bg8PD8XLgFDENjbGhHDGmGr/3r17Gsec/6Ft\nt+FrAPMByNXS3IgoV7mfB8BNue8B4I5avixlmgaMsamMsXOMsXNiWRnmYfr3749Dhw5pzOqaN2+e\nQXX++uuvqg9DPc0l0LWxadK8jLFhAPKJqNFxIeV7Rzq9yUlEsUQUQEQBYv7XOHToUFRVVUEiUfwq\nd+7caVB9s2fPVu2/9NJLICJYW1sbVGdzRZs778sAhjPGbgGIB9CPMbYDwF3GmDsAKH/Wh4DMBtBe\nrbynMq3ZIpFIkJ+fD8ZYk//iS0pKIJfLGz1/9epVWFlZ4cSJEzh9+rSxpTYrmvzCRkQLACwAAMZY\nXwDziCiCMfY5gEgAK5Q/9yuLHAAQxxj7EoovbL4A/jC+dMvC1dUVcrkcHTp0wOrVq5GQkIAjR47A\n2dkZffv2hb+/P5555hk4OTmhrKwMRUVFuHz5Mi5cuIATJ05AJpNhy5YtkEgkonhvziLQ5hXj+g1A\nXwCHlPuuAI4BSANwFICLWr4YABkArgEIbapeS3v1XR9WrVpFACgiIkLvVc7Ly8spOjqaANDUqVON\nrFA84ElaMUdI9uzZQwBMskrku+++S66urnT//n2j123JaGtePrdBTxwdHZGQkIDRo0eDiEyySuS6\ndetQUFAAFxcXRERE8IcVD8HNqyPp6enw8PBASUmJQUG9dWXHjh2YMGGCwYtXNye4eXXgzJkziIqK\nQna2MIMn+/fvh0Qiwfz58wVp39Lg5tWSe/fuYfHixaro8UIxYcIE+Pn5WdRi00LRLFeJNAW2trY6\nxRIOCwvTeOAwduxYFBQUaOS5d+8eXFxcIJVKddbTq1cvnD59WvVwpDmh7SqRfEqklhQWFuqUPyUl\nBf3791cdd+nS5ZE8Tz31FPLz82FnZwdnZ2ed6j9z5gzatGmD/Pz8pjM3U5rfx9YELFu2DC1atDBa\nfYWFhejbty88PT3x3XffwdbWFr1799Z5As6wYcOMpkmM8G6DFjDGHpks0xTOzs4a3YbNmzcjMzNT\nI4+7uztycxVzm0pLSzXiBWsDEWHlypUNBgoXM9p2G/idVwv0mWTu6OiIPXv2oHfv3sjMzISTk5PG\n+dzcXNy587/Jd7oaF1B8qFauXKlzueYCN68W6LOQXWZmJq5evYoBAwagU6dOuHTpEv74439TPAYO\nHKiq99KlS3prq62t1bus2OHm1QJ91uedN28eHjx4AACqUYbZs2cjKysLADBq1ChV3tmzZ+Odd95B\naGiozmbs0aOHztqaDdo8Qzb1ZulzG9zc3LTOe/nyZZo3b55G2t27dyklJcXgaOgPc/v2bfrll1+M\nWqclgCc5GpCx+fPPPwVZZKQpPDw8BHvaZ0r4FzYjEhgYaHFPtIqKijBmzBihZQgKv/NqydNPP43b\nt29bzMuQ+gzfiQV+5zUymZmZFvMotm3btk9kAJWHsYy/hkggIuzYsQPDhw8XpP1169Zh7NixyMvL\nM9oaEWKGdxv04P79+2jdujUKCwt1npOgL3FxcWjfvj369OljlvaEhHcbTEj9y5afffYZ/Pz8TPov\n/I8//gBjDF27dn0ijKsL3LwGsGrVKly7dg3R0dEYM2aMUZ92ffjhh5BIJHjw4AGICN26dTNa3c0G\nbQaDTb1Z+kMKbfnqq6/IysqK/P39KS4ujuRyudZlCwsLafDgwQSA5s6dS3V1dSZUatmAP6QQloqK\nCuzcuRN79uzBqVOnVMvxS6VS1NX9b83B9u3bY8iQIRg9ejSGDBkilFyLQts+Lzcvx+LgX9g4zR6L\nuPMyxu4BeACgoKm8FkoriFO7per2IqImV1+0CPMCAGPsnDb/KiwRsWoXq+56eLeBI1q4eTmixZLM\nGyu0AAMQq3ax6gZgQX1eDkdXLOnOy+HohODmZYwNUcZrS1eGxLIoGGObGWP5jLG/1dJEEYOOMdae\nMXacMXaFMXaZMTZLmS4K/U2izTNkU20ApFCsoO4DwBrARQBdhdTUgMZgAN0B/K2WtgpAtHI/GsBK\n5X5X5TXYAPBWXptUQO3uALor9x0AXFdqFIX+pjah77xBANKJ6AYRVUMRsGWEwJo0IKKTAB5eqEwU\nMeiIKJeI/lLul0IRBNIDItHfFEKbV6uYbRaIQTHohIAx1gGAP4AkiFB/QwhtXtFDiv+3Fj1kwxiz\nB7AHwGwiKlE/Jwb9jSG0ecUas000MegYYzIojPsfItqrTBaN/schtHn/BODLGPNmjFlDEXD7gMCa\ntOEAFLHngEdj0I1jjNkwxrwhcAw6pnhP/3sAqUT0pdopUehvEqG/MQJ4FYpvwRkAYoTW04C+nQBy\nAdRA0QecBCPGoDOx9t5QdAlSAFxQbq+KRX9TG3/CxhEtQncbOBy94ebliBZuXo5o4ebliBZuXo5o\n4ebliBZuXo5o4ebliJb/DwsEHRZ8CqZIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113f02c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "im = Image.open('result.png')\n",
    "im_list = np.asarray(im)\n",
    "plt.imshow(im_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45.動詞の格パターン情報抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"neko_3.txt\", mode='w') as out_file:\n",
    "    for chunks in function_1():\n",
    "        for chunk in chunks:\n",
    "            verbs = chunk.get_morphs_by_pos('動詞')\n",
    "            if len(verbs) < 1:\n",
    "                continue\n",
    "            auxs = []\n",
    "            for src in chunk.srcs:\n",
    "                aux = chunks[src].get_morphs_by_pos('助詞')\n",
    "                if len(aux) > 0:\n",
    "                    auxs.append(aux[-1])\n",
    "            out_file.write('{}\\t{}\\n'.format(verbs[0].base,' '.join(sorted(aux.surface for aux in auxs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生れる\tで\n",
      "つく\tか が\n",
      "泣く\tで\n",
      "する\tて は\n",
      "始める\tで\n",
      "見る\tは を\n",
      "聞く\tで\n",
      "捕える\tを\n",
      "煮る\tて\n",
      "食う\tて\n"
     ]
    }
   ],
   "source": [
    "with open('neko_3.txt') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline().rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 704 云う\tと\r\n",
      " 452 する\tを\r\n",
      " 333 思う\tと\r\n",
      " 202 ある\tが\r\n",
      " 199 なる\tに\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!sort neko_3.txt | uniq -c | sort -nr | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 452 する\tを\r\n",
      " 188 する\tに\r\n",
      " 159 する\tと\r\n",
      " 117 する\tが\r\n",
      " 113 する\tに を\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"^する\" neko_3.txt|sort|uniq -c|sort -r|head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 175 見る\tて\r\n",
      "  98 見る\tを\r\n",
      "  23 見る\tて て\r\n",
      "  20 見る\tから\r\n",
      "  17 見る\tと\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"^見る\" neko_3.txt|sort|uniq -c|sort -r|head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 与える\tに を\r\n",
      "   2 与える\tて に は を\r\n",
      "   2 与える\tて に を\r\n",
      "   1 与える\tけれども は を\r\n",
      "   1 与える\tか として\r\n"
     ]
    }
   ],
   "source": [
    "!grep \"^与える\" neko_3.txt|sort|uniq -c|sort -r|head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. 動詞の格フレーム情報の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"neko_4.txt\", mode='w') as out_file:\n",
    "    for chunks in function_1():\n",
    "        for chunk in chunks:\n",
    "            verbs = chunk.get_morphs_by_pos('動詞')\n",
    "            if len(verbs) < 1:\n",
    "                continue\n",
    "            a = []\n",
    "            for src in chunk.srcs:\n",
    "                if len(chunks[src].get_kaku()) > 0:\n",
    "                    a.append(chunks[src])\n",
    "            a.sort(key=lambda x: x.get_kaku())\n",
    "            out_file.write('{}\\t{}\\t{}\\n'.format(verbs[0].base,' '.join([chunk.get_kaku for chunk in a]),\\  \n",
    "                ' '.join([chunk.fuhao() for chunk in a])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生れる\tで\tどこで\n",
      "つく\tか が\t生れたか 見当が\n",
      "泣く\tで\t所で\n",
      "する\tて は\t泣いて いた事だけは\n",
      "始める\tで\tここで\n",
      "見る\tは を\t吾輩は ものを\n",
      "聞く\tで\tあとで\n",
      "捕える\tを\t我々を\n",
      "煮る\tて\t捕えて\n",
      "食う\tて\t煮て\n"
     ]
    }
   ],
   "source": [
    "with open('neko_4.txt') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline().rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. 機能動詞構文のマイニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('neko_5.txt', mode='w') as out_file:\n",
    "    for chunks in function_1():\n",
    "        for chunk in chunks:\n",
    "            verbs = chunk.get_morphs_by_pos('動詞')\n",
    "            if len(verbs) < 1:\n",
    "            b = []\n",
    "            for src in chunk.srcs:\n",
    "                if len(chunks[src].get_kaku()) > 0:\n",
    "                    b.append(chunks[src])\n",
    "            sahen = ''\n",
    "            for i in b:\n",
    "                sahen = i.get_sahen()\n",
    "                if len(sahen) > 0:\n",
    "                    chunk_remove = i\n",
    "                    break\n",
    "            b.remove(chunk_remove)\n",
    "            b.sort(key=lambda x: x.get_kaku())\n",
    "            out_file.write('{}\\t{}\\t{}\\n'.format(\n",
    "                sahen + verbs[0].base,' '.join([chunk.get_kaku for chunk in b]), \\     \n",
    "                ' '.join([chunk.fuhao() for chunk in b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  30 返事をする\r\n",
      "  21 挨拶をする\r\n",
      "  16 話をする\r\n",
      "  14 真似をする\r\n",
      "  13 喧嘩をする\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 neko_5.txt | sort | uniq -c | sort -nr | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8 真似をする\t\r\n",
      "   6 返事をする\tと\r\n",
      "   6 運動をする\t\r\n",
      "   6 喧嘩をする\t\r\n",
      "   4 挨拶をする\tから\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1,2 neko_5.txt | sort | uniq -c | sort -nr | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. 名詞から根へのパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"neko_6.txt\", mode='w') as out_file:\n",
    "    for chunks in function_1():\n",
    "        for chunk in chunks:\n",
    "            if(len(chunk.get_morphs_by_pos('名詞')) > 0):\n",
    "                out_file.write(chunk.fuhao())\n",
    "                dst = chunk.dst\n",
    "                while dst != -1:\n",
    "                    out_file.write(' -> ' + chunks[dst].fuhao())\n",
    "                    dst = chunks[dst].dst\n",
    "                out_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\n",
      "吾輩は -> 猫である\n",
      "猫である\n",
      "名前は -> 無い\n",
      "どこで -> 生れたか -> つかぬ\n",
      "見当が -> つかぬ\n",
      "何でも -> 薄暗い -> 所で -> 泣いて -> 記憶している\n",
      "所で -> 泣いて -> 記憶している\n",
      "ニャーニャー -> 泣いて -> 記憶している\n",
      "いた事だけは -> 記憶している\n"
     ]
    }
   ],
   "source": [
    "with open('neko_6.txt') as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline().rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49. 名詞間の係り受けパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neko_7.txt\", mode='w') as out_file:\n",
    "    for chunks in neco_lines():\n",
    "        indexs_noun = [i for i in range(len(chunks)) if chunks[i].chk_pos('名詞')]\n",
    "        for i, index_x in enumerate(indexs_noun[:-1]):\n",
    "            for index_y in indexs_noun[i+1:]:\n",
    "                meet_y=False          \n",
    "                index_cross=-1          \n",
    "                routes_x=set()      \n",
    "                dst=chunks[index_x].dst\n",
    "                while dst!=-1:\n",
    "                    if dst==index_y:\n",
    "                        meet_y=True           \n",
    "                        break\n",
    "                    routes_x.add(dst)           \n",
    "                    dst=chunks[dst].dst\n",
    "                if not meet_y:\n",
    "                    dst=chunks[index_y].dst\n",
    "                    while dst!=-1:\n",
    "                        if dst in routes_x:\n",
    "                            index_cross=dst  \n",
    "                            break\n",
    "                        else:\n",
    "                            dst=chunks[dst].dst\n",
    "\n",
    "                if index_cross==-1:\n",
    "                    out_file.write(chunks[index_x].noun_change('X'))\n",
    "                    dst=chunks[index_x].dst\n",
    "                    while dst!=-1:\n",
    "                        if dst==index_y:\n",
    "                            out_file.write('->'+chunks[dst].noun_change('Y', True))\n",
    "                            break\n",
    "                        else:\n",
    "                            out_file.write('->'+chunks[dst].fuhao())\n",
    "                        dst=chunks[dst].dst\n",
    "                    out_file.write('\\n')\n",
    "\n",
    "                else:\n",
    "                    a=chunks[index_x].noun_change('X')+'|'+chunks[index_y].noun_change('Y')\n",
    "                    out_file.write(a)\n",
    "                    dst=chunks[index_y].dst\n",
    "                    while dst!=index_cross:\n",
    "                        out_file.write('->'+chunks[dst].fuhao())\n",
    "                        dst=chunks[dst].dst\n",
    "                    out_file.write('|')\n",
    "                    out_file.write(chunks[index_cross].fuhao())\n",
    "                    out_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xは->Y\n",
      "Xで|Yが|つかぬ\n",
      "Xでも->薄暗い->Y\n",
      "Xでも|Y|泣いて\n",
      "Xでも|Yだけは|記憶している\n",
      "Xでも->薄暗い->所で->泣いて->Y\n",
      "Xで|Y|泣いて\n",
      "Xで|Yだけは|記憶している\n",
      "Xで->泣いて->Y\n",
      "X|Yだけは|記憶している\n",
      "X->泣いて->Y\n",
      "Xだけは->Y\n",
      "Xは|Yで->始めて->人間という->ものを|見た\n",
      "Xは|Yという->ものを|見た\n",
      "Xは|Yを|見た\n",
      "Xで->始めて->Y\n",
      "Xで->始めて->人間という->Y\n",
      "Xという->Y\n",
      "Xで|Yは|種族であったそうだ\n",
      "Xで|Yという->人間中で|種族であったそうだ\n"
     ]
    }
   ],
   "source": [
    "with open('neko_7.txt') as f:\n",
    "    for i in range(20):\n",
    "        print(f.readline().rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
